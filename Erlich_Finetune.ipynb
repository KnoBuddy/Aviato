{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Erlich Finetune.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPGc+KJtmPDieNPnmCy2Oq0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KnoBuddy/Aviato/blob/main/Erlich_Finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KnoBuddy's Colab Notebook Implementation of Erlich a text2image generator for logos"
      ],
      "metadata": {
        "id": "52dSCEODIu3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect your google drive and create a folder name test_nb"
      ],
      "metadata": {
        "id": "BjMQ2E4IJAjB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgINRyYhHa5t",
        "outputId": "da03dcc3-6a37-419c-d5e1-2495e1df86ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84f42d9-99a9-49aa-fc13-feb70e5f79b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun  9 21:03:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b503db89-a160-4242-837f-5c37a874b28f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/test_nb/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qccJ9BH8HksO",
        "outputId": "96227b9e-3669-42be-dba8-d9b88beb1347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/test_nb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NhjNFMsHyUY",
        "outputId": "f2efcbd7-475b-4d3b-f22d-2c2c22cb4509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'=1.0.8'\t\t encoders\t\t     ongo.pt\n",
            "'=2.0.0'\t\t erlich.pt\t\t     predict_util.py\n",
            " aesthetic_clip_embeds\t finetune.pt\t\t     README.md\n",
            " autoedit_api.py\t guided_diffusion\t     requirements.txt\n",
            " autoedit.py\t\t guided_diffusion.egg-info   sample.py\n",
            " bert.pt\t\t inpaint.pt\t\t     scripts\n",
            " clip_custom\t\t kl-f8.pt\t\t     setup.py\n",
            " cog_predict.py\t\t latent-diffusion\t     src\n",
            " cog.yaml\t\t ldm\t\t\t     taming-transformers\n",
            " diffusion.pt\t\t LICENSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/LAION-AI/ldm-finetune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko8txMoIIS_z",
        "outputId": "583b2b5c-beab-4d90-e153-fa38098d82ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ldm-finetune'...\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
            "remote: Compressing objects: 100% (177/177), done.\u001b[K\n",
            "remote: Total 292 (delta 134), reused 265 (delta 107), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (292/292), 1.95 MiB | 12.83 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this to update"
      ],
      "metadata": {
        "id": "1YZfzabYJJ8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhAAQgEPIqxb",
        "outputId": "e1b6e94f-dda3-4ee1-9448-cdbe599f95a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ldm-finetune/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWt_fyxBIkuC",
        "outputId": "8efcc329-6f6e-4108-8990-e1cee7a80e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/test_nb/ldm-finetune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wandb login 02a7247d36c07136ba7b90e08d6201ee8e67bc1b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xONnjlOLTALD",
        "outputId": "4ea99602-d1f5-4a66-ae7a-df3f8e7ef06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/LAION-AI/aesthetic-predictor "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zT7vEjDT74-",
        "outputId": "aeb2381c-d9c2-4253-d034-0fefa09c3be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'aesthetic-predictor'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 67 (delta 21), reused 28 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/CompVis/latent-diffusion.git\n",
        "! git clone https://github.com/CompVis/taming-transformers\n",
        "! pip install -e ./taming-transformers\n",
        "! pip install omegaconf>=2.0.0 pytorch-lightning>=1.0.8 torch-fidelity einops"
      ],
      "metadata": {
        "id": "p1XOU9I9JZ-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -e ."
      ],
      "metadata": {
        "id": "7aGekT5jJthm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r requirements.txt\n",
        "! pip install ftfy"
      ],
      "metadata": {
        "id": "bMiQJNjYJNB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "! pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LUZpsbeRf_b",
        "outputId": "971c9e68-a904-4594-b6ac-076c0ecb0bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-h_j328oo\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-h_j328oo\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.12.0+cu113)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (9.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (2022.5.18.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text encoder (required)\n",
        "! wget https://dall-3.com/models/glid-3-xl/bert.pt\n",
        "\n",
        "# ldm first stage (required)\n",
        "! wget https://dall-3.com/models/glid-3-xl/kl-f8.pt\n",
        "\n",
        "# there are several diffusion models to choose from:\n",
        "\n",
        "# original diffusion model from CompVis\n",
        "! wget https://dall-3.com/models/glid-3-xl/diffusion.pt\n",
        "\n",
        "# new model fine tuned on a cleaner dataset (will not generate watermarks, split images or blurry images)\n",
        "! wget https://dall-3.com/models/glid-3-xl/finetune.pt\n",
        "\n",
        "# inpaint\n",
        "! wget https://dall-3.com/models/glid-3-xl/inpaint.pt\n",
        "\n",
        "# erlich\n",
        "! wget -O erlich.pt https://huggingface.co/laion/erlich/raw/main/model/ema_0.9999_120000.pt\n",
        "\n",
        "# ongo\n",
        "! wget https://huggingface.co/laion/ongo/resolve/main/ongo.pt"
      ],
      "metadata": {
        "id": "eDRB_n9HKFph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generated images saved to ./output/\n",
        "# generated image embeddings saved to ./output_npy/ as npy files"
      ],
      "metadata": {
        "id": "mtDjZcxBMKOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fast PLMS sampling\n",
        "! python sample.py --model_path finetune.pt --batch_size 1 --num_batches 1 --text \"a cyberpunk girl with a scifi neuralink device on her head\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8eEudZIL8Dm",
        "outputId": "2ed04cbe-d437-4367-ddc1-2502dff4e729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "tcmalloc: large alloc 3491364864 bytes == 0x7c08000 @  0x7f3f2f080b6b 0x7f3f2f0a0379 0x7f3e74bad50e 0x7f3e74b9f7c2 0x7f3eb02294c1 0x7f3f2a1f6446 0x7f3f29ecd3f1 0x593784 0x594731 0x548cc1 0x51566f 0x549e0e 0x593fce 0x5118f8 0x549e0e 0x4bcb19 0x59582d 0x595b69 0x62026d 0x55de15 0x59af67 0x515655 0x549e0e 0x4bca8a 0x5134a6 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x604173\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mknobuddy\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.18 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/test_nb/ldm-finetune/wandb/run-20220609_211358-x9851z57\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mzany-fire-35\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/knobuddy/ongo-eval-table\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/knobuddy/ongo-eval-table/runs/x9851z57\u001b[0m\n",
            "Starting run for\ta cyberpunk girl with a scifi neuralink device on her head\n",
            "Using aesthetic embedding 9 with weight 0.5\n",
            "100% 27/27 [00:07<00:00,  3.80it/s]\n",
            "Logged prompt a cyberpunk girl with a scifi neuralink device on her head to w&b table\n",
            "Done.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mzany-fire-35\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/knobuddy/ongo-eval-table/runs/x9851z57\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220609_211358-x9851z57/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier free guidance + CLIP guidance (better adherence to prompt, much slower)\n",
        "! python sample.py --clip_guidance --model_path finetune.pt --batch_size 1 --num_batches 12 --text \"a cyberpunk girl with a scifi neuralink device on her head | trending on artstation\""
      ],
      "metadata": {
        "id": "CUgE_-TtMDZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier free guidance + CLIP guidance (better adherence to prompt, much slower)\n",
        "! python sample.py --clip_guidance --model_path finetune.pt --batch_size 2 --num_batches 1 --text \"the logo for Kno Buddy. the style of the logo is minimalist cyberpunk vector art with psychedelic trippy vaporwave colrs. a diamond between two headphones is the icon. a diamond listening to headphones symbolizes the group\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obtgRoOtVoyA",
        "outputId": "1dbb6a13-4d2f-477b-ea4a-38d726f2a5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "tcmalloc: large alloc 3491364864 bytes == 0x7258000 @  0x7fc4d81bab6b 0x7fc4d81da379 0x7fc41dce750e 0x7fc41dcd97c2 0x7fc4593634c1 0x7fc4d3330446 0x7fc4d30073f1 0x593784 0x594731 0x548cc1 0x51566f 0x549e0e 0x593fce 0x5118f8 0x549e0e 0x4bcb19 0x59582d 0x595b69 0x62026d 0x55de15 0x59af67 0x515655 0x549e0e 0x4bca8a 0x5134a6 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x604173\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mknobuddy\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.18 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/test_nb/ldm-finetune/wandb/run-20220609_212751-3v67kozz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mruby-frost-39\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/knobuddy/ongo-eval-table\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/knobuddy/ongo-eval-table/runs/3v67kozz\u001b[0m\n",
            "Starting run for\tthe logo for Kno Buddy. the style of the logo is minimalist cyberpunk vector art with psychedelic trippy vaporwave colrs. a diamond between two headphones is the icon. a diamond listening to headphones symbolizes the group\n",
            "Using aesthetic embedding 9 with weight 0.5\n",
            "100% 27/27 [00:50<00:00,  1.88s/it]\n",
            "Logged prompt the logo for Kno Buddy. the style of the logo is minimalist cyberpunk vector art with psychedelic trippy vaporwave colrs. a diamond between two headphones is the icon. a diamond listening to headphones symbolizes the group to w&b table\n",
            "Done.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mruby-frost-39\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/knobuddy/ongo-eval-table/runs/3v67kozz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220609_212751-3v67kozz/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample with an init image\n",
        "!python sample.py --init_image picture.jpg --skip_timesteps 10 --model_path finetune.pt --batch_size 6 --num_batches 6 --text \"a cyberpunk girl with a scifi neuralink device on her head\""
      ],
      "metadata": {
        "id": "QHaOoLhYMGsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier free guidance + CLIP guidance (better adherence to prompt, much slower)\n",
        "! python sample.py --clip_guidance --model_path finetune.pt --guidance_scale 30.0 --seed -1 --batch_size 1 --num_batches 1 --text \"the logo for Kno Buddy. the style of the logo is minimalist cyberpunk vector art with psychedelic trippy vaporwave colrs. a diamond between two headphones is the icon. a diamond listening to headphones symbolizes the group\" --dropout 0.1 --ema_rate 0.9999 --attention_resolutions 32,16,8 --class_cond False --diffusion_steps 1000 --image_size 32 --learn_sigma False --noise_schedule linear --num_channels 320 --num_heads 8 --num_res_blocks 2 --resblock_updown False --use_fp16 True --use_scale_shift_norm False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS1xWaTLWUUJ",
        "outputId": "89df54c3-dace-4477-9e4a-42d9e53ce990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: sample.py [-h] [--model_path MODEL_PATH] [--kl_path KL_PATH]\n",
            "                 [--bert_path BERT_PATH] [--text TEXT] [--edit EDIT]\n",
            "                 [--edit_x EDIT_X] [--edit_y EDIT_Y] [--edit_width EDIT_WIDTH]\n",
            "                 [--edit_height EDIT_HEIGHT] [--mask MASK]\n",
            "                 [--negative NEGATIVE] [--init_image INIT_IMAGE]\n",
            "                 [--skip_timesteps SKIP_TIMESTEPS] [--prefix PREFIX]\n",
            "                 [--num_batches NUM_BATCHES] [--batch_size BATCH_SIZE]\n",
            "                 [--width WIDTH] [--height HEIGHT] [--seed SEED]\n",
            "                 [--guidance_scale GUIDANCE_SCALE] [--steps STEPS] [--cpu]\n",
            "                 [--clip_score] [--clip_guidance]\n",
            "                 [--clip_guidance_scale CLIP_GUIDANCE_SCALE] [--cutn CUTN]\n",
            "                 [--ddim] [--ddpm]\n",
            "sample.py: error: unrecognized arguments: --dropout 0.1 --ema_rate 0.9999 --attention_resolutions 32,16,8 --class_cond False --diffusion_steps 1000 --image_size 32 --learn_sigma False --noise_schedule linear --num_channels 320 --num_heads 8 --num_res_blocks 2 --resblock_updown False --use_fp16 True --use_scale_shift_norm False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier free guidance + CLIP guidance (better adherence to prompt, much slower)\n",
        "! python sample.py --clip_guidance --model_path finetune.pt --guidance_scale 25.0 --seed -1 --batch_size 1 --num_batches 1 --text \"the logo for Kno Buddy. the style of the logo is minimalist cyberpunk vector art with psychedelic trippy vaporwave colrs. a diamond between two headphones is the icon. a diamond listening to headphones symbolizes the group. the name of the group KnoBuddy is spelled out across the bottom of the logo\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiQQTT4-ZXuj",
        "outputId": "49225cbe-3202-45b5-c05c-8dce5ed536be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/__init__.py\", line 721, in <module>\n",
            "    _C._initExtension(manager_path())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\", line 759, in <module>\n",
            "    from . import amp\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/__init__.py\", line 1, in <module>\n",
            "    from .autocast_mode import autocast, custom_fwd, custom_bwd  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/autocast_mode.py\", line 5, in <module>\n",
            "    import numpy as np\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/__init__.py\", line 150, in <module>\n",
            "    from . import core\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/__init__.py\", line 81, in <module>\n",
            "    from . import function_base\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/function_base.py\", line 9, in <module>\n",
            "    from numpy.core import overrides\n",
            "  File \"<frozen importlib._bootstrap>\", line 1009, in _handle_fromlist\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"sample.py\", line 9, in <module>\n",
            "    import clip\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/clip/__init__.py\", line 1, in <module>\n",
            "    from .clip import *\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/clip/clip.py\", line 8, in <module>\n",
            "    import torch\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}